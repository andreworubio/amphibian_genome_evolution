---
title: "Anuran genome size evolution is driven by relatively recent 
retrotransposon activity and by life history"
output: html_document
date: "2025-06-20"
---

```{r}
library(ape)
library(nlme)
library(dplyr)
library(ggplot2)
library(writexl)
library(MuMIn)
library(tidyr)
library(cowplot)
library(ggpubr)
library(patchwork)

```

```{r}
#Load your dataset (CSV file)
df <- read.csv("combined_data/reshaped_with_species_final.csv", header = TRUE)  # Replace with your actual file path

# Define assembly accessions to remove
to_remove <- c("GCA_009364435.1", "GCA_023970735.1", "GCA_009364455.1")

# Filter out rows with matching Assembly Accession
noe <- df[!(df$Assembly.Accession %in% to_remove), ]

head(noe)

noe$total.TEs.counts <- noe$DNA.transposons.Count + noe$Retroelements.Count
noe$total.TEs.length <- noe$DNA.transposons.Length..bp. + noe$Retroelements.Length..bp.
noe$total.TEs.percentage_final <- ((noe$DNA.transposons.Length..bp. + noe$Retroelements.Length..bp.) / noe$Genome.size) * 100
noe$Genome.size.Gb <- noe$Genome.size / 1e9

# adding TE type proportion to genome size
noe$SINEs.Percentage_2_genome <- (noe$SINEs.Length..bp./noe$Genome.size)*100
noe$Penelope.Percentage_2_genome <- (noe$Penelope.Length..bp./noe$Genome.size)*100
noe$CRE.SLACS.Percentage_2_genome <- (noe$CRE.SLACS.Length..bp./noe$Genome.size)*100
noe$L2.CR1.Rex.Percentage_2_genome <- (noe$L2.CR1.Rex.Length..bp./noe$Genome.size)*100
noe$R1.LOA.Jockey.Percentage_2_genome <- (noe$R1.LOA.Jockey.Length..bp./noe$Genome.size)*100
noe$R2.R4.NeSL.Percentage_2_genome <- (noe$R2.R4.NeSL.Length..bp./noe$Genome.size)*100
noe$RTE.Bov.B.Percentage_2_genome <- (noe$RTE.Bov.B.Length..bp./noe$Genome.size)*100
noe$L1.CIN4.Percentage_2_genome <- (noe$L1.CIN4.Length..bp./noe$Genome.size)*100
noe$Gypsy.DIRS1.Percentage_2_genome <- (noe$Gypsy.DIRS1.Length..bp./noe$Genome.size)*100
noe$BEL.Pao.Percentage_2_genome <- (noe$BEL.Pao.Length..bp./noe$Genome.size)*100
noe$Ty1.Copia.Percentage_2_genome <- (noe$Ty1.Copia.Length..bp./noe$Genome.size)*100
noe$Retroviral.Percentage_2_genome <- (noe$Retroelements.Length..bp./noe$Genome.size)*100
noe$hobo.Activator.Percentage_2_genome <- (noe$hobo.Activator.Length..bp./noe$Genome.size)*100
noe$Tc1.IS630.Pogo.Percentage_2_genome <- (noe$Tc1.IS630.Pogo.Length..bp./noe$Genome.size)*100
noe$MULE.MuDR.Percentage_2_genome <- (noe$MULE.MuDR.Length..bp./noe$Genome.size)*100
noe$PiggyBac.Percentage_2_genome <- (noe$PiggyBac.Length..bp./noe$Genome.size)*100
noe$Tourist.Harbinger.Percentage_2_genome <- (noe$Tourist.Harbinger.Length..bp./noe$Genome.size)*100
noe$Other..Mirage..Percentage_2_genome <- (noe$Other..Mirage..Length..bp./noe$Genome.size)*100

write_xlsx(noe, "combined_data/reshaped_with_species_final_Manuscript_version.xlsx")

noe$species <- gsub(" ", "_", noe$Species)  # Standardize with underscores
#data_clean$species <- tolower(data_clean$species)  # Convert to lowercase

noe$species

# Load your phylogenetic tree (Newick format)
phylo_tree <- ape::read.tree("altered_TreePL-Rooted_Anura_bestTree.tre")
phylo_tree
plot(phylo_tree)

# Standardize species names in both the dataset and the phylogeny
phylo_tree$tip.label <- gsub(" ", "_", phylo_tree$tip.label)  # Standardize with underscores

# phylo_tree$tip.label <- tolower(phylo_tree$tip.label)  # Convert to lowercase
phylo_tree
plot(phylo_tree)

# Check if all species in data are present in the phylogenetic tree tips
cat("Do species names match?", all(noe$species %in% phylo_tree$tip.label), "\n")

# Identify species in data that are not in the phylogenetic tree tips
non_matching_species <- setdiff(noe$species, phylo_tree$tip.label)

# Display the non-matching species
cat("Species not in phylogenetic tree tips:", non_matching_species, "\n")

#Remove species from the tree and dataset if they do not match
phylo_tree <- drop.tip(phylo_tree, setdiff(phylo_tree$tip.label, noe$species))
  #matching_species

phylo_tree
plot(phylo_tree)

# Check if all species in data are present in the phylogenetic tree tips
cat("Do species names match?", all(noe$species %in% phylo_tree$tip.label), "\n")

str(noe)

# Exclude specific columns from conversion
cols_to_convert <- setdiff(names(noe), c("species", "Assembly.Accession", "Species"))

# Convert all the other columns to numeric (except 'species')
noe[, cols_to_convert] <- lapply(noe[, cols_to_convert], as.numeric)
str(noe)
noe

# Check tree labels
phylo_tree$tip.label

# Check species names in the dataset
unique(noe$species)


```

#PGLS-> is the number of TE insertions correlated with genome size
```{r}
# Perform I performed a PGLS using nlme and the Pagel's lambda correlation structure
pgls_counts <- gls(Genome.size ~ SINEs.Count + Penelope.Count + CRE.SLACS.Count + L2.CR1.Rex.Count + R1.LOA.Jockey.Count + R2.R4.NeSL.Count + RTE.Bov.B.Count + L1.CIN4.Count + Gypsy.DIRS1.Count + BEL.Pao.Count + Ty1.Copia.Count + Retroviral.Count + hobo.Activator.Count + Tc1.IS630.Pogo.Count + MULE.MuDR.Count + PiggyBac.Count + Tourist.Harbinger.Count + Other..Mirage..Count + Contig.N50, data = noe, correlation = corPagel(1, phylo_tree, form = ~ species))  # pagel correlation

summary(pgls_counts)
anova(pgls_counts)
print(pgls_counts)

# Extract summary coefficients and preserve row names as a column
summary_df <- as.data.frame(summary(pgls_counts)$tTable)
summary_df$Variable <- rownames(summary_df)
summary_df <- summary_df[, c("Variable", names(summary_df)[1:4])]  # Reorder columns

# Extract ANOVA table (usually already has row names as a column)
anova_df <- as.data.frame(anova(pgls_counts))
anova_df$Term <- rownames(anova_df)
anova_df <- anova_df[, c("Term", names(anova_df)[1:(ncol(anova_df)-1)])]  # Reorder columns

# Write to Excel with variable names included
write_xlsx(
  list(
    Coefficients = summary_df,
    ANOVA = anova_df
  ),
  path = "results/pgls_results_with_names.xlsx"
)

# Extract p-values from the summary of the PGLS model
p_values_counts <- summary(pgls_counts)$tTable[, 4]  # Extracting the p-values from the tTable (4th column)

# Apply a multiple testing correction (e.g., Benjamini-Hochberg (BH) method for FDR control)
adjusted_pvalues_counts <- p.adjust(p_values_counts, method = "BH")

# Print adjusted p-values
adjusted_pvalues_counts

# Create a data frame with the adjusted p-values
adjusted_pvalues_df_counts <- data.frame(
  TE_Class = names(p_values_counts),  # Add names of the TE classes as a column
  P_Value = p_values_counts,          # Original p-values
  Adjusted_P_Value = adjusted_pvalues_counts  # Adjusted p-values
)

# Export to Excel
write_xlsx(adjusted_pvalues_df_counts, "results/number_of_elements_adjusted_pvalues.xlsx")


# Get the summary of the model to extract coefficients and p-values
model_summary_noe <- summary(pgls_counts)

# Extract the coefficients and p-values
coefficients_noe <- model_summary_noe$tTable

# View the coefficients (the first column should be the estimates, and the second column p-values)
head(coefficients_noe)

# Filter the significant TEs (e.g., p-value < 0.05)
significant_TEs_noe <- coefficients_noe[coefficients_noe[, "p-value"] < 0.05, ]

significant_TEs_noe


te_cols <- grep(".Count$", names(noe), value = TRUE)
r2_results <- data.frame(TE = character(), R2 = numeric(), stringsAsFactors = FALSE)

# Fit null model once
model_null <- gls(Genome.size ~ 1, data = noe, correlation = corPagel(1, phylo_tree, form = ~ species))
var_null <- summary(model_null)$sigma^2

# Loop through TE predictors
for (te in te_cols) {
  cat("Fitting model for:", te, "\n")
  
  # Skip constant or nearly constant predictors
  if (length(unique(na.omit(noe[[te]]))) < 3) {
    cat(" -> Skipped (not enough variation)\n")
    next
  }
  
  formula <- as.formula(paste("Genome.size ~", te))
  
  # Try fitting the model; if it fails, skip
  tryCatch({
    model <- gls(formula, data = noe, correlation = corPagel(1, phylo_tree, form = ~ species))
    var_full <- summary(model)$sigma^2
    r2_pseudo <- 1 - (var_full / var_null)
    r2_results <- rbind(r2_results, data.frame(TE = te, R2 = r2_pseudo))
  }, error = function(e) {
    cat(" -> Model failed:", conditionMessage(e), "\n")
  })
}

# View RÂ² values
print(r2_results)

library(writexl)
write_xlsx(r2_results, "results/number_of_elements_TE_pseudo_R2_results.xlsx")

```


#PGLS-> is the length of TE insertions correlated with genome size
```{r}
# Perform a PGLS using nlme and the Pagel's lambda correlation structure
pgls_Length <- gls(Genome.size.Gb ~ SINEs.Length..bp. + Penelope.Length..bp. + CRE.SLACS.Length..bp. + L2.CR1.Rex.Length..bp. + R1.LOA.Jockey.Length..bp. + R2.R4.NeSL.Length..bp. + RTE.Bov.B.Length..bp. + L1.CIN4.Length..bp. + Gypsy.DIRS1.Length..bp. + BEL.Pao.Length..bp. + Ty1.Copia.Length..bp. + Retroviral.Length..bp. + hobo.Activator.Length..bp. + Tc1.IS630.Pogo.Length..bp. + MULE.MuDR.Length..bp. + PiggyBac.Length..bp. + Tourist.Harbinger.Length..bp. + Other..Mirage..Length..bp. + Contig.N50, data = noe, correlation = corPagel(1, phylo_tree, form = ~ species))  # pagel correlation

summary(pgls_Length)
anova(pgls_Length)
print(pgls_Length)


# Extract summary coefficients and preserve row names as a column
summary_Length <- as.data.frame(summary(pgls_Length)$tTable)
summary_Length$Variable <- rownames(summary_df)
summary_Length <- summary_Length[, c("Variable", names(summary_Length)[1:4])]  # Reorder columns

# Extract ANOVA table (usually already has row names as a column)
anova_Length <- as.data.frame(anova(pgls_Length))
anova_Length$Term <- rownames(anova_Length)
anova_Length <- anova_Length[, c("Term", names(anova_Length)[1:(ncol(anova_Length)-1)])]  # Reorder columns

# Write to Excel with variable names included
write_xlsx(
  list(
    Coefficients = summary_Length,
    ANOVA = anova_Length
  ),
  path = "results/Length_of_elements_results_with_names.xlsx"
)

# Extract p-values from the summary of the PGLS model
p_values_Length <- summary(pgls_Length)$tTable[, 4]  # Extracting the p-values from the tTable (4th column)

# Apply a multiple testing correction (e.g., Benjamini-Hochberg (BH) method for FDR control)
adjusted_pvalues_Length <- p.adjust(p_values_Length, method = "BH")

# Print adjusted p-values
adjusted_pvalues_Length

# Create a data frame with the adjusted p-values
adjusted_pvalues_df_Length <- data.frame(
  TE_Class = names(p_values_Length),  # Add names of the TE classes as a column
  P_Value = p_values_Length,          # Original p-values
  Adjusted_P_Value = adjusted_pvalues_Length  # Adjusted p-values
)

# Export to Excel
write_xlsx(adjusted_pvalues_df_Length, "results/Length_of_elements_adjusted_pvalues.xlsx")

#calculating Rsquare
library(nlme)
library(writexl)

# Get all TE length predictor column names (assuming they end in ".Length..bp.")
te_length_cols <- grep(".Length..bp.$", names(noe), value = TRUE)

# Prepare results dataframe
r2_results_length <- data.frame(TE = character(), R2 = numeric(), stringsAsFactors = FALSE)

# Fit null model once (intercept-only, same correlation structure)
model_null <- gls(
  Genome.size ~ 1,
  data = noe,
  correlation = corPagel(1, phylo_tree, form = ~ species)
)
var_null <- summary(model_null)$sigma^2

# Loop through each TE length predictor
for (te in te_length_cols) {
  cat("Fitting model for:", te, "\n")
  
  # Skip constant or nearly constant predictors
  if (length(unique(na.omit(noe[[te]]))) < 3) {
    cat(" -> Skipped (not enough variation)\n")
    next
  }
  
  # Fit the model with TE length
  formula <- as.formula(paste("Genome.size ~", te))
  
  tryCatch({
    model <- gls(
      formula,
      data = noe,
      correlation = corPagel(1, phylo_tree, form = ~ species)
    )
    var_full <- summary(model)$sigma^2
    r2_pseudo <- 1 - (var_full / var_null)
    
    r2_results_length <- rbind(r2_results_length, data.frame(TE = te, R2 = r2_pseudo))
  }, error = function(e) {
    cat(" -> Model failed:", conditionMessage(e), "\n")
  })
}

# Print and save the results
print(r2_results_length)

# Save as Excel
write_xlsx(r2_results_length, "results/length_TE_pseudo_R2_results.xlsx")
```

#PGLS-> is the percent (of total genome) of TE insertions correlated with genome size
```{r}
# Perform a PGLS using nlme and the Pagel's lambda correlation structure
pgls_Percentage <- gls(Genome.size.Gb ~ SINEs.Percentage_2_genome + Penelope.Percentage_2_genome + CRE.SLACS.Percentage_2_genome + L2.CR1.Rex.Percentage_2_genome + R1.LOA.Jockey.Percentage_2_genome + R2.R4.NeSL.Percentage_2_genome + RTE.Bov.B.Percentage_2_genome + L1.CIN4.Percentage_2_genome + Gypsy.DIRS1.Percentage_2_genome + BEL.Pao.Percentage_2_genome + Ty1.Copia.Percentage_2_genome + Retroviral.Percentage_2_genome + hobo.Activator.Percentage_2_genome + Tc1.IS630.Pogo.Percentage_2_genome + MULE.MuDR.Percentage_2_genome + PiggyBac.Percentage_2_genome + Tourist.Harbinger.Percentage_2_genome + Other..Mirage..Percentage_2_genome + Contig.N50, data = noe, correlation = corPagel(1, phylo_tree, form = ~ species))  # pagel correlation

summary(pgls_Percentage)
anova(pgls_Percentage)
print(pgls_Percentage)

# Extract summary coefficients and preserve row names as a column
summary_Percentage <- as.data.frame(summary(pgls_Percentage)$tTable)
summary_Percentage$Variable <- rownames(summary_Percentage)
summary_Percentage <- summary_Percentage[, c("Variable", names(summary_Percentage)[1:4])]  # Reorder columns

# Extract ANOVA table (usually already has row names as a column)
anova_Percentage <- as.data.frame(anova(pgls_Percentage))
anova_Percentage$Term <- rownames(anova_Percentage)
anova_Percentage <- anova_Percentage[, c("Term", names(anova_Percentage)[1:(ncol(anova_Percentage)-1)])]  # Reorder columns

# Write to Excel with variable names included
write_xlsx(
  list(
    Coefficients = summary_Percentage,
    ANOVA = anova_Percentage
  ),
  path = "results/Percentage_of_elements_results_with_names.xlsx"
)

# Extract p-values from the summary of the PGLS model
p_values_Percentage <- summary(pgls_Percentage)$tTable[, 4]  # Extracting the p-values from the tTable (4th column)

# Apply a multiple testing correction (e.g., Benjamini-Hochberg (BH) method for FDR control)
adjusted_pvalues_Percentage <- p.adjust(p_values_Percentage, method = "BH")

# Print adjusted p-values
adjusted_pvalues_Percentage

# Create a data frame with the adjusted p-values
adjusted_pvalues_df_Percentage <- data.frame(
  TE_Class = names(p_values_Percentage),  # Add names of the TE classes as a column
  P_Value = p_values_Percentage,          # Original p-values
  Adjusted_P_Value = adjusted_pvalues_Percentage  # Adjusted p-values
)

# Export to Excel
write_xlsx(adjusted_pvalues_df_Percentage, "results/Percentage_of_elements_adjusted_pvalues.xlsx")

# Get all TE length predictor column names (assuming they end in ".Length..bp.")
te_per_cols <- grep(".Percentage_2_genome$", names(noe), value = TRUE)

# Prepare results dataframe
r2_results_length <- data.frame(TE = character(), R2 = numeric(), stringsAsFactors = FALSE)

# Fit null model once (intercept-only, same correlation structure)
model_null <- gls(
  Genome.size ~ 1,
  data = noe,
  correlation = corPagel(1, phylo_tree, form = ~ species)
)
var_null <- summary(model_null)$sigma^2

# Loop through each TE length predictor
for (te in te_per_cols) {
  cat("Fitting model for:", te, "\n")
  
  # Skip constant or nearly constant predictors
  if (length(unique(na.omit(noe[[te]]))) < 3) {
    cat(" -> Skipped (not enough variation)\n")
    next
  }
  
  # Fit the model with TE length
  formula <- as.formula(paste("Genome.size ~", te))
  
  tryCatch({
    model <- gls(
      formula,
      data = noe,
      correlation = corPagel(1, phylo_tree, form = ~ species)
    )
    var_full <- summary(model)$sigma^2
    r2_pseudo <- 1 - (var_full / var_null)
    
    r2_results_length <- rbind(r2_results_length, data.frame(TE = te, R2 = r2_pseudo))
  }, error = function(e) {
    cat(" -> Model failed:", conditionMessage(e), "\n")
  })
}

# Print and save the results
print(r2_results_length)

# Save as Excel
write_xlsx(r2_results_length, "results/length_TE_pseudo_R2_results.xlsx")

```

